{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sparse_Matrix_Multiplication.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO9i116I/21xXKeUtJPeamg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andres8bit/parallel-computing/blob/main/Sparse_Matrix_Multiplication.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3gN6ZNg_lM_",
        "outputId": "e0b9b117-7020-4fb8-e790-260b20a1c4f1"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-azp89doy\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-azp89doy\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=193f3673c0905a9950367681faab27193128a6e9de84adf53c18aaa115175340\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-e804_10f/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAifeB2X_uUL",
        "outputId": "e3632d6f-56ce-4583-9dcd-9e85362ff213"
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmOSQhDQwSJ5"
      },
      "source": [
        "# The following cells implement sparce matrix multiplication kernels.\r\n",
        "# Each one uses a different matrix representation format.\r\n",
        "# The first uses Compressed Sparse Row (CSR) format. In which only non-zero elements\r\n",
        "# are stored in an array, and thier corresponding column and row index are stored in\r\n",
        "# seperate 1D arrays.\r\n",
        "#\r\n",
        "# The Second uses padding and transposing, storing the matrix in ELL format.\r\n",
        "# This second verson takes better advantage of memory bandwith inorder to reduce\r\n",
        "# latency.However this comes with a cost of more memory usage.\r\n",
        "# \r\n",
        "# Finaly a third hybrid implemntation is adviced wich comines idead from both \r\n",
        "# the CSR and ELL kernels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8xyfXfR_vg8",
        "outputId": "e6f73b17-eed3-4a17-fc92-e291642bf806"
      },
      "source": [
        "%%cu\r\n",
        "#include<iostream>\r\n",
        "\r\n",
        "__global__ void sparse_matrix_csr_kernel(int num_rows, float* data,\r\n",
        "                              int* col_index, int *row_ptr, float* x, float*y);\r\n",
        "\r\n",
        "void print_array(float *array, int width);\r\n",
        "int main(){\r\n",
        "    int host_row_ptr [] = {0,2,2,5,7};\r\n",
        "    int host_col_index [] = {0,2,1,2,3,0,3};\r\n",
        "    float host_data[] = {3,1,2,4,1,1,1};\r\n",
        "    float host_x[] = {2,4,6,1};\r\n",
        "    float host_y[] = {0,0,0,0};\r\n",
        "\r\n",
        "    int* device_row_ptr; int* device_col_index;\r\n",
        "    float* device_data; float* device_x; float* device_y;\r\n",
        "    \r\n",
        "    cudaMalloc ((void **) &device_data, 7 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_row_ptr, 5 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_col_index, 7 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_x, 4 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_y, 4 * sizeof(float));\r\n",
        "    \r\n",
        "    cudaMemcpy(device_data,host_data, 7 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_row_ptr,host_row_ptr, 5 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_col_index,host_col_index, 7 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_x,host_x, 4 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_y,host_y, 4 *sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    dim3 dim_grid(4);\r\n",
        "    dim3 dim_block(4);\r\n",
        "\r\n",
        "    sparse_matrix_csr_kernel<<<dim_grid,dim_block>>>(4,device_data,\r\n",
        "                            device_col_index,device_row_ptr,device_x,device_y); \r\n",
        "  \r\n",
        "    cudaMemcpy(host_y,device_y, 4 * sizeof(float), cudaMemcpyDeviceToHost);\r\n",
        "\r\n",
        "    print_array(host_y,4);\r\n",
        "    \r\n",
        "    cudaFree(device_data);\r\n",
        "    cudaFree(device_row_ptr);\r\n",
        "    cudaFree(device_col_index);\r\n",
        "    cudaFree(device_x);\r\n",
        "    cudaFree(device_y);\r\n",
        "\r\n",
        "    return 0;\r\n",
        "}\r\n",
        "\r\n",
        "void print_array(float *array, int width){\r\n",
        "        for(int i = 0; i < width; i++)\r\n",
        "        printf(\"%d\\t\", (int)array[i]);\r\n",
        "    \r\n",
        "  printf(\"\\n\");\r\n",
        "}\r\n",
        "\r\n",
        "__global__ void sparse_matrix_csr_kernel(int num_rows, float* data,\r\n",
        "                              int* col_index, int *row_ptr, float* x, float*y)\r\n",
        "{\r\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\r\n",
        "    int row_start = 0;\r\n",
        "    int row_end = 0;\r\n",
        "    float dot = 0;\r\n",
        "    \r\n",
        "    if (row < num_rows){\r\n",
        "        dot = 0;\r\n",
        "        row_start = row_ptr[row];\r\n",
        "        row_end = row_ptr[row + 1];\r\n",
        "        \r\n",
        "        for (int elem = row_start; elem < row_end; elem++)\r\n",
        "              dot += data[elem] * x[col_index[elem]];\r\n",
        "        \r\n",
        "        y[row] += dot;\r\n",
        "    }\r\n",
        "}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\t0\t33\t3\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_L2heC0Fr2W",
        "outputId": "baf0d369-4f67-441f-c7dc-1cf91de0413c"
      },
      "source": [
        "%%cu\r\n",
        "#include<iostream>\r\n",
        "\r\n",
        "__global__ void sparse_matrix_vector_ell_kernel(int num_rows,float* data,int* col_index,\r\n",
        "                                                int num_elem, float* x,float* y);\r\n",
        "void print_array(float *array, int width);\r\n",
        "int main(){\r\n",
        "    float host_data[] = {3,0,2,1,1,0,4,1,0,0,1,0};\r\n",
        "    int host_col_index [] = {0,0,1,0,2,0,2,3,0,0,3,0};\r\n",
        "    float host_x[] = {2,4,6,1};\r\n",
        "    float host_y[] = {0,0,0,0};\r\n",
        "\r\n",
        "    int* device_col_index;\r\n",
        "    float* device_data; float* device_x; float* device_y;\r\n",
        "    \r\n",
        "    cudaMalloc ((void **) &device_data, 7 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_col_index, 7 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_x, 4 * sizeof(float));\r\n",
        "    cudaMalloc ((void **) &device_y, 4 * sizeof(float));\r\n",
        "    \r\n",
        "    cudaMemcpy(device_data,host_data, 7 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_col_index,host_col_index, 7 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_x,host_x, 4 * sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "    cudaMemcpy(device_y,host_y, 4 *sizeof(float),cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "    dim3 dim_grid(2);\r\n",
        "    dim3 dim_block(32);\r\n",
        "\r\n",
        "    sparse_matrix_vector_ell_kernel<<<dim_grid,dim_block>>>(4,device_data,\r\n",
        "                            device_col_index,3,device_x,device_y); \r\n",
        "  \r\n",
        "    cudaMemcpy(host_y,device_y, 4 * sizeof(float), cudaMemcpyDeviceToHost);\r\n",
        "\r\n",
        "    print_array(host_y,4);\r\n",
        "    \r\n",
        "    cudaFree(device_data);\r\n",
        "    cudaFree(device_col_index);\r\n",
        "    cudaFree(device_x);\r\n",
        "    cudaFree(device_y);\r\n",
        "\r\n",
        "    return 0;\r\n",
        "}\r\n",
        "\r\n",
        "void print_array(float *array, int width){\r\n",
        "        for(int i = 0; i < width; i++)\r\n",
        "        printf(\"%d\\t\", (int)array[i]);\r\n",
        "    \r\n",
        "  printf(\"\\n\");\r\n",
        "}\r\n",
        "\r\n",
        "__global__ void sparse_matrix_vector_ell_kernel(int num_rows,float* data,int* col_index,\r\n",
        "                                                int num_elem, float* x,float* y)\r\n",
        "{\r\n",
        "    int row = blockIdx.x * blockDim.x + threadIdx.x;\r\n",
        "    float dot = 0;\r\n",
        "    if (row < num_rows){\r\n",
        "        dot = 0;\r\n",
        "        for (int i = 0; i < num_elem;i++){\r\n",
        "            dot += data[row + i * num_rows] * x[col_index[row+i*num_rows]];\r\n",
        "        }\r\n",
        "        y[row] += dot;\r\n",
        "    }\r\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12\t0\t32\t2\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}